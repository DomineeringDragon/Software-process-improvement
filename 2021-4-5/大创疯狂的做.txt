大创我一人C！
设计了整体的框架：
后端：爬虫、对爬取的内容进行分类，保存至数据库中，框架采用FLASK
前端：通过VUE搭建前端，通过输入单词，获取数据库中的对应句子

# Ted语料库需求分析

## 模块划分

### 前段搭建
#### 前端技术
前端预定采用VUE，需要实现的功能有
1、查找：
①通过关键字查找符合要求的所有句子
②通过找到的句子，返回所属的对应全文
③通过该文章，返回对应的TED官网信息？(可不实现)
2、增加：
①通过给定文章的URL，自动添加至数据库

1、2都需要给后端发请求，可以写一个公用模块，如api_request
### 后端搭建
#### 后端框架
预定采用FLASK
#### 资料获取
通过scrapy、api爬取稿件，内容分为文稿、标题、作者信息、分类
①需要完成自动的爬取
②通过给定URL，爬取对应文章，若有TXT文件则添加，没有则返回错误信息

#### 资料处理
至少需要把一整篇文章按句子划分再导入数据库。
#### 导入数据库
至少需要2个表，一个表存文章，字段由文章ID、作者、标题、内容、相关TED官网信息构成；另一个存每个文章的句子，由句子ID、文章ID(外键)、句子内容、作者、标题构成。
要求：
①若官网有下架文章，本地数据库不需要进行删除

